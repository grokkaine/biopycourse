{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda create -n biopy37 python=3.7\n",
    "conda install jupyterlab matplotlib tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driven by practicality as we are for the purpose of this course, we will dwelve directly into an example of using DL. We will gradually learn more things as we do things.\n",
    "\n",
    "Most developed deep learning APIs:\n",
    "- Tensorflow\n",
    "    - [Keras](https://keras.io/)\n",
    "- PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN essentials\n",
    "\n",
    "- task: classification, handwritten\n",
    "- method: multi-layered perceptron\n",
    "- concepts: NN architecture and training loop\n",
    "- python libraries: native, keras, tensorflow, pytorch\n",
    "- task: text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape (flatten) and scale images\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "image=train_images[0].reshape(28, 28)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(\"Label:\", train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to one hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layered perceptron (feed forward network)\n",
    "\n",
    "- Each hiden layer is formed by neurons called perceptrons\n",
    "- A perceptron is a binary linear classifier\n",
    "    - inputs: a flat array $x_i$\n",
    "    - one output per neuron j: $y_j$\n",
    "    - a transformation of input into output (activation function):\n",
    "        - linear separator\n",
    "        - sigmoid function\n",
    "\n",
    "$z_j= \\sum_i {w_{ij} x_i} + b_j$\n",
    "\n",
    "$y_j = f(z_j) = \\frac{1}{1 + e^{-z_j}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../img/perceptron.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"../img/perceptron.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input layer: sequential (flattened) image\n",
    "- hidden layers: perceptrons\n",
    "- output layer: softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../img/ffn.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"../img/ffn.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# defining the NN structure\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='sigmoid', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(512, activation='sigmoid', input_shape=(512,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning process\n",
    "\n",
    "NNs are supervised learning structures!\n",
    "- forward propagation: all training data is fed to the network and y is predicted\n",
    "- estimate the loss: difference between prediction and label\n",
    "- backpropagation: the loss information is propagated backwards layer by layer, and the neuron weights are adjusted\n",
    "- global optimization: the parameters (weights and biases) must be adjusted in such a way that the loss function presented above is minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"../img/NN_learning.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"../img/NN_learning.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient descent (main optimization technique)\n",
    "The weights in small increments with the help of the calculation of the derivative (or gradient) of the loss function, which allows us to see in which direction “to descend” towards the global minimum. Most optimizers are based on gradient descent, an algorithm that is very eficient on GPUs today, but gives local optima.\n",
    "- Epochs and batches. The optimization is done in general in batches of data in the successive iterations (epochs) of all the dataset that we pass to the network in each iteration. \"epochs\" are complete runs through the dataset. Batches are used because the whole dataset is hard to be passed through the network at once.\n",
    "\n",
    "```\n",
    "- 469 number of batches\n",
    "128 * 469 ~= 60000 images (number of samples)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 2.3260 - accuracy: 0.1102\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 2.0545 - accuracy: 0.2552\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.5536 - accuracy: 0.4409\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 1.2167 - accuracy: 0.5548\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 1.0346 - accuracy: 0.6229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2301a071b88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.9686 - accuracy: 0.6306\n",
      "0.9685710668563843 0.6305999755859375\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- slightly smaller accuracy on the test data compared to training data (model overfits on the training data)\n",
    "\n",
    "Questions:\n",
    "- Why do we need several epochs?\n",
    "- What is the main computer limitation when it comes to batches?\n",
    "- How many epochs are needed, and what is the danger associated with using too many or too few?\n",
    "\n",
    "Reading:\n",
    "- https://medium.com/onfido-tech/machine-learning-101-be2e0a86c96a\n",
    "\n",
    "\n",
    "### Run a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "prediction=network.predict(test_images[0:9])\n",
    "y_true_cls = np.argmax(test_labels[0:9], axis=1)\n",
    "y_pred_cls = np.argmax(prediction, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(8,8))\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "  ax.imshow(test_images[i].reshape(28,28), cmap = 'BuGn')\n",
    "  xlabel = \"True: {0}, Pred: {1}\".format(y_true_cls[i], y_pred_cls[i]) \n",
    "  ax.set_xlabel(xlabel)\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical essentials\n",
    "\n",
    "How is the animal brain capable of deciding a type from a sequence of sensory inputs? What defines a dog in the image of a dog? What in the wording will make you say this is a happy person who pretends being sad? How many pictures of a dog must a child see in order to correctly label a dog? Deep learning, from an algorithmic perspective, is the application of advanced multi-layered filters to learn hidden features in data representation. Many of the methods that are used today in DL, such as most neural network types (and not only), went through a 20 years long pause due to the fact that the computing machines avalable at the era were too slow to produce wanted results. It was several things that precipitated their return in 2010:\n",
    "- Graphical processors. A GPU has thousands of cores that are specialized in concomitant linear operations. This provided the infrastructure on which \"deep\" algorithms perform the best.\n",
    "- The maturity of cloud computing. This enables third parties to use DL methodologies at scale, and with small operating costs.\n",
    "- Big data. Most AI needs models to be trained on a lot of data, thus AI needs a sufficient level of data availability. The massive acumulation of data (not only in biology) is a very recent phenomenon.\n",
    "\n",
    "As with everything else in this course, DL is a science in itself, and contains thousands pages of theory. For an in-depth reading we recommend this book, written by some of the early specialists in neural network: http://www.deeplearningbook.org/. It is today possibly the top bestseller in the field of machine learning (also, it is free).\n",
    "\n",
    "Python was an early favorite for DL, and initial libraries such as Theano started an approach based on defining the problem via Python, then compiling a program that can be executed faster than a regular code on either CPU and GPU. Later in 2013 Google made Tensorflow available as open source library and different other DL libraries have mushroomed. The difficulty of operating such libraries comes from their specialist language and the Pythonic way to solve this and open AI to everyone was to make a library that would be able to use various DL engines, while simplifying the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification\n",
    "\n",
    "The purpose is to cathegorize films into good or bad based on their reviews. Data is vectorized into binary.\n",
    "\n",
    "**layer activation**\n",
    "\n",
    "What happens during layer activation? Basically a set of tensor operations are being performed. A simplistic way to understand this is operations done on array of matrices, while the atomic operation would be:\n",
    "\n",
    "```\n",
    "output = relu(dot(W, input) + b)\n",
    "```\n",
    ", where the weight matrix W shape is (input_dim (10000), 16) and b is a bias term. In linear algebra terms, this will project the input data onto a 16 dimensional space. The more dimensions, the more features, the more confusion, and more computing cost BUT also more complex representations.\n",
    "\n",
    "Task:\n",
    "- Perform sentiment analysis using the code below!\n",
    "- Plot the accuracy vs loss in both the training and validation data, on the history.history dictionary. Use more epochs. What do you notice? How many epochs do you think you need? What if you monitor for 100000 epochs?\n",
    "- We were using 2 hidden layers. Try to use 1 or 3 hidden layers and see how it affects validation and test accuracy.\n",
    "- Adjust the learning rate.\n",
    "- Try to use layers with more hidden units or less hidden units: 32 units, 64 units...\n",
    "- Try to use the mse loss function instead of binary_crossentropy.\n",
    "- Try to use the tanh activation (an activation that was popular in the early days of neural networks) instead of relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "print(max([max(sequence) for sequence in train_data]))\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])\n",
    "\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "p = model.predict(x_test)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, SimpleRNN\n",
    "\n",
    "max_features = 10000  # number of words to consider as features\n",
    "maxlen = 500  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, batch_size))\n",
    "model.add(SimpleRNN(batch_size, return_sequences=True))\n",
    "model.add(SimpleRNN(batch_size))  # This last layer only returns the last outputs.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(input_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task:\n",
    "- Figure out how to use LSTMs to improve the model accuracy. Also figure out what LSTMs are :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common NN headaches\n",
    "\n",
    "\n",
    "**Overfitting:** Gradient descent is the core of NN fitting. Optimization adjusts a model optimally on the training data, while the overfitting quantifies how bad the trained model would perform on data it has never seen before. The tension between fitness and generalization is what defines machine learning.\n",
    "\n",
    "While the model is trained, it starts with being under-fit, but after more features are identified and more cleaning is done, the model starts to become over-fit and vallidation metrics reach a \"stable state\" or start degrading. The patterns that the model not learn are specific to the training data, but not to the test data. How do we combat this?\n",
    "\n",
    "- Add more data. The most succesfull AI today is trained on an umbelievably large set of labeled data. Somewhere deep underground, billions of minions work all day in their smart homes, driving smart cars, being smart about labeling their photos on FB. Similarly their machines tag single cell IDs on RNA probes.\n",
    "- Regularization. And yet the data is always not sufficient... Regularisation involves either modulating the quantity of information that your model is allowed to store, or to adding constraints on what information it is allowed to store.\n",
    "- Hyperparametrization: DL models typically parametrize the model, which means that the fit is different when a different combination of parameters is used\n",
    "\n",
    "Tasks:\n",
    "- Reduce network size in one of the previous NNs, and then increase it a lot. Plot this for a number of epochs and see when does overfitting occur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
