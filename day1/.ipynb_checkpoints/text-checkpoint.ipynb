{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text manipulation is quite simplified in Python thanks to a wide variety of packages. It is generally advisable not to reinvent the wheels, so only perform quick and dirty text parsing when it is really necessary.\n",
    "\n",
    "### File IO, streaming, serialization\n",
    "\n",
    "Here is a basic raw text file opening template in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f =  open('path/to/file.txt','r')\n",
    "# #f.readlines()\n",
    "# for l in f:\n",
    "#     #do stuff\n",
    "#     print l\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to read text from the standard input? (Useful for pipelining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-1-dd343f7516e3>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-dd343f7516e3>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    print line\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "#use ike this: cat file.txt | python script.py\n",
    "import sys\n",
    "for line in sys.stdin:\n",
    "    # do suff\n",
    "    print line\n",
    "\n",
    "# there is a dedicated module to text IO\n",
    "#import io\n",
    "#t = io.TextIO()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling\n",
    "\n",
    "This in Python jargon means object serialization, a very important feature allowing you to save on disk the contents of a Python datastructure directly, in a specially compressed or sometimes binary format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'first': [1, 'two'], 'second': {'five', 3, 4}}\n"
     ]
    }
   ],
   "source": [
    "d = {'first': [1,\"two\"], 'second': set([3, 4, 'five'])}\n",
    "import pickle\n",
    "with open('dumpfile.pkl','wb') as fout:\n",
    "    pickle.dump(d, fout)\n",
    "with open('dumpfile.pkl','rb') as fin:\n",
    "    d2 = pickle.load(fin)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON\n",
    "\n",
    "A short word for JavaScript Object Notation, .json became ubiquitous as a simple data interchange format mainly in remote Web API calls and microtransactions. Json is easily loaded into native Python datastructures. An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"first\": [1, \"two\"], \"second\": [3, 4, \"five\"]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "#json_string = json.dumps([1, 2, 3, \"a\", \"b\", \"c\"])\n",
    "d = {'first': [1,\"two\"], 'second': [3, 4, 'five']}\n",
    "json_string = json.dumps(d)\n",
    "print(json_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing and regular expressions\n",
    "\n",
    "Used for any raw text format in biology, such as (FASTA, FASTAQ, PDB, VCF, GFF, SAM).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: FASTA parsing\n",
    "\n",
    "Open the file containing all peptide sequences in the human body.\n",
    "How many unknown peptides does it contain?\n",
    "How many unique genes and transcripts are in there for the unknown peptides?\n",
    "Output a tab separated file containing the gene id and transcript id for each unknown peptide.\n",
    "\n",
    "Observation:\n",
    "Usage of Biopython and pandas modules.\n",
    "\n",
    "Task:\n",
    "Order the chromosomes by the number of unknown peptides versus the total number of peptides they translate.\n",
    "\n",
    ">ENSP00000388523 pep:known chromosome:GRCh38:7:142300924:142301432:1 gene:ENSG00000226660 transcript:ENST00000455382 gene_biotype:TR_V_gene transcript_biotype:TR_V_gene\n",
    "MDTWLVCWAIFSLLKAGLTEPEVTQTPSHQVTQMGQEVILRCVPISNHLYFYWYRQILGQ\n",
    "KVEFLVSFYNNEISEKSEIFDDQFSVERPDGSNFTLKIRSTKLEDSAMYFCASSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99436 28828 28828 11116 70608\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "f = open('data/Homo_sapiens.GRCh38.pep.all.fa','r')\n",
    "peptides = {}\n",
    "for l in f:\n",
    "    if l[0]=='>':\n",
    "        #print l.strip().split()\n",
    "        record = {}\n",
    "        r = l.strip('\\n').split()\n",
    "        pepid = r[0][1:]\n",
    "        record['pep'] = 1 if r[1].split(':')[1]=='known' else 0\n",
    "        record['gene'] = r[3].split(':')[1]\n",
    "        record['transcript'] = r[4].split(':')[1]\n",
    "        peptides[pepid] = record\n",
    "f.close()\n",
    "\n",
    "##using regular expressions to match all known peptides\n",
    "nupep2 = 0\n",
    "import re\n",
    "#pattern = re.compile('^>.*(known).*')\n",
    "pattern = re.compile('^>((?!known).)*$')\n",
    "with open('data/Homo_sapiens.GRCh38.pep.all.fa','r') as f:\n",
    "    for l in f:\n",
    "        if pattern.search(l) is not None: nupep2 += 1 \n",
    "\n",
    "npep = len(peptides)\n",
    "upep = set([pepid for pepid in peptides if peptides[pepid]['pep']==0]) #unknown peptides\n",
    "nunknown = len(upep)\n",
    "genes = set([peptides[pepid]['gene'] for pepid in upep])\n",
    "trans = set([peptides[pepid]['transcript'] for pepid in upep])\n",
    "print npep, nupep2, nunknown, len(genes), len(ntrans)\n",
    "\n",
    "\n",
    "with open('unknown_peptides.txt','w') as f:\n",
    "    for pepid in upep:\n",
    "        f.write('\\t'.join([pepid, peptides[pepid]['gene'], peptides[pepid]['transcript']])+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-045956fa1344>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfasta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfasta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "f = open('data/Homo_sapiens.GRCh38.pep.all.fa','r')\n",
    "from Bio import SeqIO\n",
    "fasta = SeqIO.parse(f,'fasta')\n",
    "\n",
    "i = 0\n",
    "name, sequence = fasta.id, fasta.seq.tostring()\n",
    "if len(sequence)<100 and len(sequence)>20:\n",
    "    i += 1\n",
    "    print i\n",
    "    print \"Name\",name\n",
    "    print \"Sequence\",sequence\n",
    "    if i > 5: break\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML parsing\n",
    "\n",
    "XML is a general file format used for data interchange, especially among different applications. One of the most popular use in Biology is the SBML format, that aims to store a biological model specification, no matter how specific that model may be.\n",
    "\n",
    "Task:\n",
    "\n",
    "Download a curated SBML file from the BioModels database:\n",
    "http://www.ebi.ac.uk/biomodels-main/\n",
    "\n",
    "Find out how many reactions the file contains.\n",
    "\n",
    "Extra task:\n",
    "\n",
    "Make a simplified XML file of the reactants and their k-values for each reaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbml {'version': '4', 'metaid': '_000000', 'level': '2'}\n",
      "model {'id': 'BIOMD0000000001', 'metaid': '_000001', 'name': 'Edelstein1996 - EPSP ACh event'}\n",
      "notes {}\n",
      "annotation {}\n",
      "listOfCompartments {}\n",
      "listOfSpecies {}\n",
      "listOfParameters {}\n",
      "listOfReactions {}\n",
      "listOfEvents {}\n",
      "reaction {'name': 'React0', 'id': 'React0', 'metaid': '_000016', 'sboTerm': 'SBO:0000177'}\n",
      "reaction {'name': 'React1', 'id': 'React1', 'metaid': '_000017', 'sboTerm': 'SBO:0000177'}\n",
      "reaction {'name': 'React2', 'id': 'React2', 'metaid': '_000018', 'sboTerm': 'SBO:0000181'}\n",
      "reaction {'name': 'React3', 'id': 'React3', 'metaid': '_000019', 'sboTerm': 'SBO:0000177'}\n",
      "reaction {'name': 'React4', 'id': 'React4', 'metaid': '_000020', 'sboTerm': 'SBO:0000177'}\n",
      "reaction {'name': 'React5', 'id': 'React5', 'metaid': '_000021', 'sboTerm': 'SBO:0000181'}\n",
      "reaction {'name': 'React6', 'id': 'React6', 'metaid': '_000022', 'sboTerm': 'SBO:0000181'}\n",
      "reaction {'name': 'React7', 'id': 'React7', 'metaid': '_000023', 'sboTerm': 'SBO:0000177'}\n",
      "reaction {'name': 'React8', 'id': 'React8', 'metaid': '_000024', 'sboTerm': 'SBO:0000177'}\n",
      "reaction {'name': 'React9', 'id': 'React9', 'metaid': '_000025', 'sboTerm': 'SBO:0000181'}\n",
      "reaction {'name': 'React10', 'id': 'React10', 'metaid': '_000026', 'sboTerm': 'SBO:0000181'}\n",
      "reaction {'name': 'React11', 'id': 'React11', 'metaid': '_000027', 'sboTerm': 'SBO:0000181'}\n",
      "reaction {'name': 'React12', 'id': 'React12', 'metaid': '_000028', 'sboTerm': 'SBO:0000177'}\n",
      "reaction {'name': 'React13', 'id': 'React13', 'metaid': '_000029', 'sboTerm': 'SBO:0000177'}\n",
      "reaction {'name': 'React14', 'id': 'React14', 'metaid': '_000030', 'sboTerm': 'SBO:0000181'}\n",
      "reaction {'name': 'React15', 'id': 'React15', 'metaid': '_000031', 'sboTerm': 'SBO:0000181'}\n",
      "reaction {'name': 'React16', 'id': 'React16', 'metaid': '_000032', 'sboTerm': 'SBO:0000181'}\n",
      "species {'name': 'BasalACh2', 'metaid': '_000003', 'sboTerm': 'SBO:0000297', 'compartment': 'comp1', 'id': 'BLL', 'initialAmount': '0'}\n",
      "BLL\n",
      "species {'name': 'IntermediateACh', 'metaid': '_000004', 'sboTerm': 'SBO:0000297', 'compartment': 'comp1', 'id': 'IL', 'initialAmount': '0'}\n",
      "IL\n",
      "species {'name': 'ActiveACh', 'metaid': '_000005', 'sboTerm': 'SBO:0000297', 'compartment': 'comp1', 'id': 'AL', 'initialAmount': '0'}\n",
      "AL\n",
      "species {'name': 'Active', 'metaid': '_000006', 'sboTerm': 'SBO:0000420', 'compartment': 'comp1', 'id': 'A', 'initialAmount': '0'}\n",
      "A\n",
      "species {'name': 'BasalACh', 'metaid': '_000007', 'sboTerm': 'SBO:0000297', 'compartment': 'comp1', 'id': 'BL', 'initialAmount': '0'}\n",
      "BL\n",
      "species {'name': 'Basal', 'metaid': '_000008', 'sboTerm': 'SBO:0000420', 'compartment': 'comp1', 'id': 'B', 'initialAmount': '1.66057788110262E-21'}\n",
      "B\n",
      "species {'name': 'DesensitisedACh2', 'metaid': '_000009', 'sboTerm': 'SBO:0000297', 'compartment': 'comp1', 'id': 'DLL', 'initialAmount': '0'}\n",
      "DLL\n",
      "species {'name': 'Desensitised', 'metaid': '_000010', 'sboTerm': 'SBO:0000420', 'compartment': 'comp1', 'id': 'D', 'initialAmount': '0'}\n",
      "D\n",
      "species {'name': 'IntermediateACh2', 'metaid': '_000011', 'sboTerm': 'SBO:0000297', 'compartment': 'comp1', 'id': 'ILL', 'initialAmount': '0'}\n",
      "ILL\n",
      "species {'name': 'DesensitisedACh', 'metaid': '_000012', 'sboTerm': 'SBO:0000297', 'compartment': 'comp1', 'id': 'DL', 'initialAmount': '0'}\n",
      "DL\n",
      "species {'name': 'Intermediate', 'metaid': '_000013', 'sboTerm': 'SBO:0000420', 'compartment': 'comp1', 'id': 'I', 'initialAmount': '0'}\n",
      "I\n",
      "species {'name': 'ActiveACh2', 'metaid': '_000014', 'sboTerm': 'SBO:0000297', 'compartment': 'comp1', 'id': 'ALL', 'initialAmount': '0'}\n",
      "ALL\n",
      "[<Element 'reaction' at 0x7f30d7906490>, <Element 'reaction' at 0x7f30d7906f10>, <Element 'reaction' at 0x7f30d78f3950>, <Element 'reaction' at 0x7f30d7838390>, <Element 'reaction' at 0x7f30d7838d90>, <Element 'reaction' at 0x7f30d78447d0>, <Element 'reaction' at 0x7f30d78511d0>, <Element 'reaction' at 0x7f30d7851bd0>, <Element 'reaction' at 0x7f30d78625d0>, <Element 'reaction' at 0x7f30d7862f90>, <Element 'reaction' at 0x7f30d78a7950>, <Element 'reaction' at 0x7f30d7873350>, <Element 'reaction' at 0x7f30d7873d10>, <Element 'reaction' at 0x7f30d787d710>, <Element 'reaction' at 0x7f30d788f110>, <Element 'reaction' at 0x7f30d788f950>, <Element 'reaction' at 0x7f30d40e81d0>]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.ElementTree(file='data/curated_sbml.xml')\n",
    "#tree = ET.parse(open('data/curated_sbml.xml'))\n",
    "root = tree.getroot()\n",
    "print root.tag, root.attrib\n",
    "for child in root:\n",
    "    print child.tag, child.attrib\n",
    "    for child2 in child:\n",
    "        print child2.tag, child2.attrib\n",
    "\n",
    "#print tree.write(sys.stdout)\n",
    "for elem in root.iter('reaction'):\n",
    "    print elem.tag, elem.attrib\n",
    "\n",
    "for elem in root.iter('species'):\n",
    "    print elem.tag, elem.attrib\n",
    "    print elem.get('id')\n",
    "\n",
    "print tree.findall('.//reaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping\n",
    "\n",
    "This is concerned with automatic information processing from teh Internet.\n",
    "\n",
    "Task:\n",
    "- Create your own web crawlers, to mine the relevant articles from your favorite journals. \n",
    "\n",
    "[BeautifulSoup](http://www.pythonforbeginners.com/python-on-the-web/beautifulsoup-4-python/) is loved by hackers. Aside from html it can also parse xml.\n",
    "\n",
    "Here is a small script that will list all web anchors from Reddit main page (an anchod is a html tag normally used to provide hyperlinks and reference points inside a web page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#content\n",
      "http://www.reddit.com/r/Allsvenskan/\n",
      "http://www.reddit.com/r/Art/\n",
      "http://www.reddit.com/r/AskReddit/\n",
      "http://www.reddit.com/r/askscience/\n",
      "http://www.reddit.com/r/aww/\n",
      "http://www.reddit.com/r/books/\n",
      "http://www.reddit.com/r/creepy/\n",
      "http://www.reddit.com/r/dataisbeautiful/\n",
      "http://www.reddit.com/r/DIY/\n",
      "http://www.reddit.com/r/Documentaries/\n",
      "http://www.reddit.com/r/EarthPorn/\n",
      "http://www.reddit.com/r/europe/\n",
      "http://www.reddit.com/r/explainlikeimfive/\n",
      "http://www.reddit.com/r/Fitness/\n",
      "http://www.reddit.com/r/food/\n",
      "http://www.reddit.com/r/funny/\n",
      "http://www.reddit.com/r/Futurology/\n",
      "http://www.reddit.com/r/gadgets/\n",
      "http://www.reddit.com/r/gaming/\n",
      "http://www.reddit.com/r/GetMotivated/\n",
      "http://www.reddit.com/r/gifs/\n",
      "http://www.reddit.com/r/history/\n",
      "http://www.reddit.com/r/IAmA/\n",
      "http://www.reddit.com/r/InternetIsBeautiful/\n",
      "http://www.reddit.com/r/intresseklubben/\n",
      "http://www.reddit.com/r/Jokes/\n",
      "http://www.reddit.com/r/LifeProTips/\n",
      "http://www.reddit.com/r/listentothis/\n",
      "http://www.reddit.com/r/mildlyinteresting/\n",
      "http://www.reddit.com/r/movies/\n",
      "http://www.reddit.com/r/Music/\n",
      "http://www.reddit.com/r/news/\n",
      "http://www.reddit.com/r/nosleep/\n",
      "http://www.reddit.com/r/nottheonion/\n",
      "http://www.reddit.com/r/OldSchoolCool/\n",
      "http://www.reddit.com/r/personalfinance/\n",
      "http://www.reddit.com/r/philosophy/\n",
      "http://www.reddit.com/r/photoshopbattles/\n",
      "http://www.reddit.com/r/pics/\n",
      "http://www.reddit.com/r/science/\n",
      "http://www.reddit.com/r/Showerthoughts/\n",
      "http://www.reddit.com/r/space/\n",
      "http://www.reddit.com/r/spop/\n",
      "http://www.reddit.com/r/sports/\n",
      "http://www.reddit.com/r/svenskpolitik/\n",
      "http://www.reddit.com/r/SWARJE/\n",
      "http://www.reddit.com/r/sweden/\n",
      "http://www.reddit.com/r/swedishproblems/\n",
      "http://www.reddit.com/r/television/\n",
      "http://www.reddit.com/r/tifu/\n",
      "http://www.reddit.com/r/todayilearned/\n",
      "http://www.reddit.com/r/TwoXChromosomes/\n",
      "http://www.reddit.com/r/UpliftingNews/\n",
      "http://www.reddit.com/r/videos/\n",
      "http://www.reddit.com/r/worldnews/\n",
      "http://www.reddit.com/r/WritingPrompts/\n",
      "http://www.reddit.com/subreddits/\n",
      "http://www.reddit.com/\n",
      "http://www.reddit.com/r/all\n",
      "http://www.reddit.com/r/random/\n",
      "http://www.reddit.com/r/gadgets/\n",
      "http://www.reddit.com/r/sports/\n",
      "http://www.reddit.com/r/gaming/\n",
      "http://www.reddit.com/r/pics/\n",
      "http://www.reddit.com/r/worldnews/\n",
      "http://www.reddit.com/r/videos/\n",
      "http://www.reddit.com/r/AskReddit/\n",
      "http://www.reddit.com/r/aww/\n",
      "http://www.reddit.com/r/Music/\n",
      "http://www.reddit.com/r/funny/\n",
      "http://www.reddit.com/r/news/\n",
      "http://www.reddit.com/r/movies/\n",
      "http://www.reddit.com/r/books/\n",
      "http://www.reddit.com/r/europe/\n",
      "http://www.reddit.com/r/history/\n",
      "http://www.reddit.com/r/food/\n",
      "http://www.reddit.com/r/philosophy/\n",
      "http://www.reddit.com/r/television/\n",
      "http://www.reddit.com/r/Jokes/\n",
      "http://www.reddit.com/r/Art/\n",
      "http://www.reddit.com/r/DIY/\n",
      "http://www.reddit.com/r/space/\n",
      "http://www.reddit.com/r/Documentaries/\n",
      "http://www.reddit.com/r/Fitness/\n",
      "http://www.reddit.com/r/askscience/\n",
      "http://www.reddit.com/r/nottheonion/\n",
      "http://www.reddit.com/r/sweden/\n",
      "http://www.reddit.com/r/todayilearned/\n",
      "http://www.reddit.com/r/personalfinance/\n",
      "http://www.reddit.com/r/gifs/\n",
      "http://www.reddit.com/r/listentothis/\n",
      "http://www.reddit.com/r/IAmA/\n",
      "http://www.reddit.com/r/TwoXChromosomes/\n",
      "http://www.reddit.com/r/creepy/\n",
      "http://www.reddit.com/r/nosleep/\n",
      "http://www.reddit.com/r/GetMotivated/\n",
      "http://www.reddit.com/r/WritingPrompts/\n",
      "http://www.reddit.com/r/LifeProTips/\n",
      "http://www.reddit.com/r/EarthPorn/\n",
      "http://www.reddit.com/r/explainlikeimfive/\n",
      "http://www.reddit.com/r/Showerthoughts/\n",
      "http://www.reddit.com/r/Futurology/\n",
      "http://www.reddit.com/r/photoshopbattles/\n",
      "http://www.reddit.com/r/mildlyinteresting/\n",
      "http://www.reddit.com/r/dataisbeautiful/\n",
      "http://www.reddit.com/r/Allsvenskan/\n",
      "http://www.reddit.com/r/tifu/\n",
      "http://www.reddit.com/r/svenskpolitik/\n",
      "http://www.reddit.com/r/OldSchoolCool/\n",
      "http://www.reddit.com/r/UpliftingNews/\n",
      "http://www.reddit.com/r/spop/\n",
      "http://www.reddit.com/r/InternetIsBeautiful/\n",
      "http://www.reddit.com/r/swedishproblems/\n",
      "http://www.reddit.com/r/SWARJE/\n",
      "http://www.reddit.com/r/intresseklubben/\n",
      "http://www.reddit.com/r/science/\n",
      "http://www.reddit.com/subreddits/\n",
      "/\n",
      "http://www.reddit.com/\n",
      "http://www.reddit.com/new/\n",
      "http://www.reddit.com/rising/\n",
      "http://www.reddit.com/controversial/\n",
      "http://www.reddit.com/top/\n",
      "http://www.reddit.com/gilded/\n",
      "http://www.reddit.com/wiki/\n",
      "http://www.reddit.com/ads/\n",
      "https://www.reddit.com/login\n",
      "javascript:void(0)\n",
      "http://www.reddit.com/wiki/search\n",
      "http://www.reddit.com/wiki/search\n",
      "/password\n",
      "http://www.reddit.com/submit\n",
      "http://www.reddit.com/submit?selftext=true\n",
      "/gold?goldtype=code&source=progressbar\n",
      "/gold/about\n",
      "/r/goldbenefits\n",
      "http://en.wikipedia.org/wiki/Pacific_Time_Zone\n",
      "None\n",
      "/newsletter\n",
      "#\n",
      "javascript:void(0)\n",
      "javascript:void(0)\n",
      "https://m.youtube.com/watch?v=O_4OfD-wmGs\n",
      "/domain/m.youtube.com/\n",
      "http://www.reddit.com/user/Mr_Self__Destruct\n",
      "http://www.reddit.com/r/Music/\n",
      "http://www.reddit.com/r/Music/comments/33yp3x/metallica_sad_but_true_heavy_metal/\n",
      "#\n",
      "#\n",
      "/r/Fitness/comments/33yoo0/lifting_and_ape_index/\n",
      "/r/Fitness/\n",
      "http://www.reddit.com/user/WeeLittleShenanigans\n",
      "http://www.reddit.com/r/Fitness/\n",
      "http://www.reddit.com/r/Fitness/comments/33yoo0/lifting_and_ape_index/\n",
      "#\n",
      "#\n",
      "/r/AskReddit/comments/33ypco/whats_a_story_your_grandparents_told_you_that/\n",
      "/r/AskReddit/\n",
      "http://www.reddit.com/user/Vilokthoria\n",
      "http://www.reddit.com/r/AskReddit/\n",
      "http://www.reddit.com/r/AskReddit/comments/33ypco/whats_a_story_your_grandparents_told_you_that/\n",
      "#\n",
      "#\n",
      "/r/Music/comments/33yp43/bored_dj_at_a_strip_club/\n",
      "/r/Music/\n",
      "http://www.reddit.com/user/xcancerificx\n",
      "http://www.reddit.com/r/Music/\n",
      "http://www.reddit.com/r/Music/comments/33yp43/bored_dj_at_a_strip_club/\n",
      "#\n",
      "#\n",
      "http://imgur.com/8PE2dQ1&jfOv5Mt#1\n",
      "http://imgur.com/8PE2dQ1&jfOv5Mt#1\n",
      "/domain/imgur.com/\n",
      "http://www.reddit.com/user/Insertfuckgivenhere\n",
      "http://www.reddit.com/r/gaming/\n",
      "http://www.reddit.com/r/gaming/comments/33yp58/paca_plus_aka_my_new_favorite_game_xpost_from/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/vjNm4Ai.png?1\n",
      "http://i.imgur.com/vjNm4Ai.png?1\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/KlassyBoy\n",
      "http://www.reddit.com/r/sweden/\n",
      "http://www.reddit.com/r/sweden/comments/33ymj4/en_guide_till_tf2_ft_uisterpuck_ps_fler_av_er/\n",
      "#\n",
      "#\n",
      "http://gfycat.com/SlushyShoddyCassowary\n",
      "http://gfycat.com/SlushyShoddyCassowary\n",
      "/domain/gfycat.com/\n",
      "http://www.reddit.com/user/Moodh\n",
      "http://www.reddit.com/r/Allsvenskan/\n",
      "http://www.reddit.com/r/Allsvenskan/comments/33yivo/martin_ericsson_rullar_in_segermålet_för_häcken/\n",
      "#\n",
      "#\n",
      "/r/Jokes/comments/33yoo8/life_is_like_a_box_of_chocolates/\n",
      "/r/Jokes/\n",
      "http://www.reddit.com/user/LeTruth\n",
      "http://www.reddit.com/r/Jokes/\n",
      "http://www.reddit.com/r/Jokes/comments/33yoo8/life_is_like_a_box_of_chocolates/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/TNQnQRL.gif\n",
      "http://i.imgur.com/TNQnQRL.gif\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/amlb146\n",
      "http://www.reddit.com/r/funny/\n",
      "http://www.reddit.com/r/funny/comments/33ypat/me_while_flirting/\n",
      "#\n",
      "#\n",
      "/r/AskReddit/comments/33ypch/if_every_time_you_looked_at_someone_they_would/\n",
      "/r/AskReddit/\n",
      "http://www.reddit.com/user/Allegretta\n",
      "http://www.reddit.com/r/AskReddit/\n",
      "http://www.reddit.com/r/AskReddit/comments/33ypch/if_every_time_you_looked_at_someone_they_would/\n",
      "#\n",
      "#\n",
      "/r/random\n",
      "http://www.reddit.com/wiki/selfserve\n",
      "http://www.reddit.com/advertising\n",
      "http://www.reddit.com/subreddits/\n",
      "/r/FluidMechanics\n",
      "/r/ImaginaryWesteros\n",
      "/r/perfect_response\n",
      "/r/turtlesonalligators\n",
      "/r/AppleWatch\n",
      "/r/trendingsubreddits/comments/33wi5r/trending_subreddits_for_20150426_rfluidmechanics/\n",
      "https://www.youtube.com/watch?v=_JC_wIWUC2U\n",
      "https://www.youtube.com/watch?v=_JC_wIWUC2U\n",
      "/domain/youtube.com/\n",
      "http://www.reddit.com/user/AChimimunima\n",
      "http://www.reddit.com/r/videos/\n",
      "http://www.reddit.com/r/videos/comments/33xtdn/hit_by_avalanche_in_everest_basecamp_25042015/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/ZEroinM.jpg\n",
      "http://i.imgur.com/ZEroinM.jpg\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/Valens\n",
      "http://www.reddit.com/r/funny/\n",
      "http://www.reddit.com/r/funny/comments/33xoys/russian_closet/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/yDlFd2q.gif\n",
      "http://i.imgur.com/yDlFd2q.gif\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/MrVanillacoke\n",
      "http://www.reddit.com/r/gifs/\n",
      "http://www.reddit.com/r/gifs/comments/33xpma/the_alternate_lord_of_the_rings_plot/\n",
      "#\n",
      "#\n",
      "http://static.boredpanda.com/blog/wp-content/uploads/2015/04/night-sky-stars-milky-way-photography-36__880.jpg\n",
      "http://static.boredpanda.com/blog/wp-content/uploads/2015/04/night-sky-stars-milky-way-photography-36__880.jpg\n",
      "/domain/static.boredpanda.com/\n",
      "http://www.reddit.com/user/BlackShadowRose\n",
      "http://www.reddit.com/r/pics/\n",
      "http://www.reddit.com/r/pics/comments/33xkij/starry_night_sky_over_clam_waters/\n",
      "#\n",
      "#\n",
      "https://i.imgur.com/8eE1wok.gifv\n",
      "https://i.imgur.com/8eE1wok.gifv\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/Isai76\n",
      "http://www.reddit.com/r/gaming/\n",
      "http://www.reddit.com/r/gaming/comments/33xcy7/close_call/\n",
      "#\n",
      "#\n",
      "http://www.sentinelsource.com/features/technology/japan-plans-to-land-rover-on-moon-in/article_aec6919e-ef32-5b61-8a55-ca7ccacefafd.html\n",
      "/domain/sentinelsource.com/\n",
      "http://www.reddit.com/user/Stewpid\n",
      "http://www.reddit.com/r/worldnews/\n",
      "http://www.reddit.com/r/worldnews/comments/33x7iz/japan_plans_to_land_rover_on_moon_in_2018/\n",
      "#\n",
      "#\n",
      "http://stuffdutchpeoplelike.com/2011/07/26/dutch-swears-with-diseases/\n",
      "http://stuffdutchpeoplelike.com/2011/07/26/dutch-swears-with-diseases/\n",
      "/domain/stuffdutchpeoplelike.com/\n",
      "http://www.reddit.com/user/sacara\n",
      "http://www.reddit.com/r/todayilearned/\n",
      "http://www.reddit.com/r/todayilearned/comments/33x68w/til_in_the_netherlands_people_swear_with_diseases/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/tMfLvmF.jpg\n",
      "http://i.imgur.com/tMfLvmF.jpg\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/Valens\n",
      "http://www.reddit.com/r/aww/\n",
      "http://www.reddit.com/r/aww/comments/33x53z/the_iron_throne/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/TGrAQNl.jpg\n",
      "http://i.imgur.com/TGrAQNl.jpg\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/Austere1\n",
      "http://www.reddit.com/r/mildlyinteresting/\n",
      "http://www.reddit.com/r/mildlyinteresting/comments/33xadn/this_breakfast_menu_uses_the_archer_font/\n",
      "#\n",
      "#\n",
      "http://www.seattletimes.com/seattle-news/anonymous-donor-pays-off-landslide-victims-360k-mortgage/\n",
      "http://www.seattletimes.com/seattle-news/anonymous-donor-pays-off-landslide-victims-360k-mortgage/\n",
      "/domain/seattletimes.com/\n",
      "http://www.reddit.com/user/NO__CAPE\n",
      "http://www.reddit.com/r/UpliftingNews/\n",
      "http://www.reddit.com/r/UpliftingNews/comments/33xsn2/anonymous_donor_pays_off_360000_mortgage_for_man/\n",
      "#\n",
      "#\n",
      "http://imgur.com/a/KBFD2\n",
      "/domain/imgur.com/\n",
      "http://www.reddit.com/user/JacksonCash\n",
      "http://www.reddit.com/r/DIY/\n",
      "http://www.reddit.com/r/DIY/comments/33x371/made_my_hallway_floor_look_less_awful/\n",
      "#\n",
      "#\n",
      "/r/AskReddit/comments/33wv9k/who_are_some_onehit_wonders_in_fields_other_than/\n",
      "/r/AskReddit/\n",
      "http://www.reddit.com/user/POCKALEELEE\n",
      "http://www.reddit.com/r/AskReddit/\n",
      "http://www.reddit.com/r/AskReddit/comments/33wv9k/who_are_some_onehit_wonders_in_fields_other_than/\n",
      "#\n",
      "#\n",
      "http://www.rollingstone.com/movies/news/super-troopers-2-officially-a-go-after-crowdfunding-4-4-million-20150425#ixzz3YM1O5kDW\n",
      "http://www.rollingstone.com/movies/news/super-troopers-2-officially-a-go-after-crowdfunding-4-4-million-20150425#ixzz3YM1O5kDW\n",
      "/domain/rollingstone.com/\n",
      "http://www.reddit.com/user/annekar\n",
      "http://www.reddit.com/r/movies/\n",
      "http://www.reddit.com/r/movies/comments/33wuxz/super_troopers_2_officially_a_go_after/\n",
      "#\n",
      "#\n",
      "http://www.post-gazette.com/news/state/2015/04/26/Study-Majority-of-Americans-prefer-gun-rights-over-expanded-gun-control/stories/201504260131\n",
      "/domain/post-gazette.com/\n",
      "http://www.reddit.com/user/ercax\n",
      "http://www.reddit.com/r/news/\n",
      "http://www.reddit.com/r/news/comments/33wy9p/study_majority_of_americans_prefer_gun_rights/\n",
      "#\n",
      "#\n",
      "http://jakarta.coconuts.co/2015/04/17/there-are-vampire-squirrels-giant-fluffy-tails-stalking-jungles-borneo\n",
      "http://jakarta.coconuts.co/2015/04/17/there-are-vampire-squirrels-giant-fluffy-tails-stalking-jungles-borneo\n",
      "/domain/jakarta.coconuts.co/\n",
      "http://www.reddit.com/user/BirdPersonJr\n",
      "http://www.reddit.com/r/nottheonion/\n",
      "http://www.reddit.com/r/nottheonion/comments/33xifo/scientists_prove_vampire_squirrels_of_borneo_have/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/MH0BkpR.jpg\n",
      "http://i.imgur.com/MH0BkpR.jpg\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/fourlanterns\n",
      "http://www.reddit.com/r/photoshopbattles/\n",
      "http://www.reddit.com/r/photoshopbattles/comments/33xwsa/psbattle_this_baby_being_held_by_a_horseheaded_man/\n",
      "#\n",
      "#\n",
      "/r/Showerthoughts/comments/33wx1b/when_i_was_a_kid_people_got_really_pissed_if_you/\n",
      "/r/Showerthoughts/\n",
      "http://www.reddit.com/user/fatalis_vox\n",
      "http://www.reddit.com/r/Showerthoughts/\n",
      "http://www.reddit.com/r/Showerthoughts/comments/33wx1b/when_i_was_a_kid_people_got_really_pissed_if_you/\n",
      "#\n",
      "#\n",
      "/r/IAmA/comments/33wtmk/iama_92_year_old_woman_from_stuttgart_germany_and/\n",
      "/r/IAmA/comments/33wtmk/iama_92_year_old_woman_from_stuttgart_germany_and/\n",
      "/r/IAmA/\n",
      "http://www.reddit.com/user/Jasoni92\n",
      "http://www.reddit.com/r/IAmA/\n",
      "http://www.reddit.com/r/IAmA/comments/33wtmk/iama_92_year_old_woman_from_stuttgart_germany_and/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/dldG7pQ.gifv\n",
      "http://i.imgur.com/dldG7pQ.gifv\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/Isai76\n",
      "http://www.reddit.com/r/sports/\n",
      "http://www.reddit.com/r/sports/comments/33ws83/high_school_baseball_player_catches_a_curve_ball/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/ZO9M6Dr.jpg\n",
      "http://i.imgur.com/ZO9M6Dr.jpg\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/Prooffread3r\n",
      "http://www.reddit.com/r/OldSchoolCool/\n",
      "http://www.reddit.com/r/OldSchoolCool/comments/33x2zw/mata_hari_1910s/\n",
      "#\n",
      "#\n",
      "http://www.futurism.co/wp-content/uploads/2015/04/Science_Apr-26th_2015.jpg\n",
      "http://www.futurism.co/wp-content/uploads/2015/04/Science_Apr-26th_2015.jpg\n",
      "/domain/futurism.co/\n",
      "http://www.reddit.com/user/Portis403\n",
      "http://www.reddit.com/r/Futurology/\n",
      "http://www.reddit.com/r/Futurology/comments/33xd0d/this_week_in_science_genetically_modifying_human/\n",
      "#\n",
      "#\n",
      "/r/LifeProTips/comments/33x2oi/lpt_when_using_google_or_apple_maps_tapping_the/\n",
      "/r/LifeProTips/comments/33x2oi/lpt_when_using_google_or_apple_maps_tapping_the/\n",
      "/r/LifeProTips/\n",
      "http://www.reddit.com/user/victorykings\n",
      "http://www.reddit.com/r/LifeProTips/\n",
      "http://www.reddit.com/r/LifeProTips/comments/33x2oi/lpt_when_using_google_or_apple_maps_tapping_the/\n",
      "#\n",
      "#\n",
      "/r/askscience/comments/33xuxu/if_sound_could_travel_through_space_how_loud/\n",
      "/r/askscience/\n",
      "http://www.reddit.com/user/ImTheConan\n",
      "http://www.reddit.com/r/askscience/\n",
      "http://www.reddit.com/r/askscience/comments/33xuxu/if_sound_could_travel_through_space_how_loud/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/Z7HpG0q.jpg\n",
      "http://i.imgur.com/Z7HpG0q.jpg\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/DarthButane\n",
      "http://www.reddit.com/r/EarthPorn/\n",
      "http://www.reddit.com/r/EarthPorn/comments/33wmj9/a_different_kind_of_beauty_twilight_on_the_tundra/\n",
      "#\n",
      "#\n",
      "http://i.imgur.com/OtIMjqf.png\n",
      "http://i.imgur.com/OtIMjqf.png\n",
      "/domain/i.imgur.com/\n",
      "http://www.reddit.com/user/termderd\n",
      "http://www.reddit.com/r/space/\n",
      "http://www.reddit.com/r/space/comments/33wgqf/i_took_my_nephews_to_kennedy_space_center_in/\n",
      "#\n",
      "#\n",
      "http://www.reddit.com/?count=25&after=t3_33wgqf\n",
      "http://www.reddit.com/r/random\n",
      "http://www.reddit.com/blog/\n",
      "http://www.reddit.com/about/\n",
      "http://www.reddit.com/about/team/\n",
      "http://www.reddit.com/code/\n",
      "http://www.reddit.com/advertising/\n",
      "http://www.reddit.com/jobs/\n",
      "http://www.reddit.com/rules/\n",
      "http://www.reddit.com/wiki/faq/\n",
      "http://www.reddit.com/wiki/\n",
      "http://www.reddit.com/wiki/reddiquette/\n",
      "http://www.reddit.com/wiki/transparency/\n",
      "http://www.reddit.com/contact/\n",
      "http://alienblue.org\n",
      "http://redditama.reddit.com/\n",
      "http://i.reddit.com\n",
      "http://www.reddit.com/buttons/\n",
      "http://www.reddit.com/gold/about/\n",
      "http://redditmarket.com\n",
      "http://redditgifts.com\n",
      "http://reddit.tv\n",
      "http://radioreddit.com\n",
      "http://www.reddit.com/help/useragreement\n",
      "http://www.reddit.com/help/privacypolicy\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "\n",
    "redditFile = urllib2.urlopen(\"http://www.reddit.com\")\n",
    "redditHtml = redditFile.read()\n",
    "redditFile.close()\n",
    "\n",
    "soup = BeautifulSoup(redditHtml)\n",
    "redditAll = soup.find_all(\"a\")\n",
    "for links in soup.find_all('a'):\n",
    "    print (links.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
